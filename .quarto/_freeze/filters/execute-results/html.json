{
  "hash": "fc7fa42269bac6bb44e8cf9b690ee449",
  "result": {
    "markdown": "---\ntitle: \"Edge and Corner Detection in R\"\n---\n\n\n# 1. Edge Detection\n\n## Initial Setup\n\n::: {.cell}\n\n```{.r .cell-code}\n# load libraries\nsuppressPackageStartupMessages({\n    library(imager)\n    library(ggplot2)\n    library(patchwork)\n})\n\n# load image from file into R as a cimg object\nimg <- load.image(\"data/image1.png\")\nclass(img)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"cimg\"         \"imager_array\" \"numeric\"     \n```\n:::\n:::\n\n\nUsing the `imager` library, all `cimg` objects are represented as 4-dimensional arrays. The dimensions represent: width, height, depth, and colour. In our case, our input image is already in grayscale, and we are only concerned with each pixel value, thus the dimensions for depth and colour are largely ignored. Nonetheless, we have to initialize our image as well as all subsequent filters and images in our code to contain all four dimensions so that they will be able to convolve.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# see dimensions of image\ndim(img)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 276 182   1   1\n```\n:::\n\n```{.r .cell-code}\n# view summary of image data\nimg\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nImage. Width: 276 pix Height: 182 pix Depth: 1 Colour channels: 1 \n```\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# helper function applies convolution to an image given a filter\napply_convolution <- function(image, filter) {\n    # Get dimensions of the image and the filter\n    img_dim <- dim(image)\n    filt_dim <- dim(filter)\n\n    # Define padding size\n    padding <- floor(filt_dim[1] / 2)\n\n    # initialize padded image as empty array\n    img_padded <- array(0, dim = c(\n        img_dim[1] + 2 * padding, img_dim[2] + 2 * padding, img_dim[3], img_dim[4]\n    ))\n\n    # populate padded image array with image pixels\n    img_padded[\n        (1 + padding):(img_dim[1] + padding), # width\n        (1 + padding):(img_dim[2] + padding), , # height\n    ] <- image\n\n    # initialize convolved image as empty array\n    img_convolved <- array(0, dim = img_dim)\n\n    # iterate each pixel in image and convolve with filter\n    for (i in 1:img_dim[1]) {\n        for (j in 1:img_dim[2]) {\n            pixel_convolved <- 0\n            for (k in 1:filt_dim[1]) {\n                for (l in 1:filt_dim[2]) {\n                    pixel_convolved <- pixel_convolved +\n                        filter[k, l, , ] *\n                            img_padded[i + k - 1, j + l - 1, , ]\n                }\n            }\n            img_convolved[i, j, , ] <- pixel_convolved\n        }\n    }\n\n    return(as.cimg(img_convolved))\n}\n\n\n# helper function displays images, given an image and title\nplot_img <- function(img, title = \"\") {\n    # convert image to dataframe\n    img_df <- as.data.frame(img)\n\n    # generate plot of dataframe\n    plot <- ggplot(img_df, aes(x, y)) + # nolint\n        # define rasterization\n        geom_raster(aes(fill = value), show.legend = FALSE) + # nolint\n        # define color scale (grayscale)\n        scale_fill_gradient(low = \"black\", high = \"white\") +\n        # fix pixel ratio / aspect ratio\n        coord_fixed() +\n        # reverse y scale (image orientation)\n        scale_y_reverse() +\n        # set title\n        ggtitle(title) +\n        # remove all graphical details from plot besides image\n        theme_void()\n\n    return(plot)\n}\n\n# display the original image\nplot_img(img, \"Original Image\")\n```\n\n::: {.cell-output-display}\n![](filters_files/figure-html/setup-3-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n\\newpage\n\n## (a)\nImplement convolution process of smoothing Image 1 with a 5 x 5 Gaussian Filter with &sigma; = 1 and 2, plot the corresponding output images.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# function applies a kxk Gaussian filter to an image with a sigma value\napply_gaussian <- function(img, ksize, sigma) {\n    # initialize x and y vectors around 0, e.g. [-2, -1, 0, 1, 2]\n    center <- floor(ksize / 2)\n    x <- y <- seq(-center, center, 1)\n\n    # Gaussian function\n    gauss <- outer(x, y, function(x, y) {\n        exp(-(x^2 + y^2) / (2 * sigma^2))\n    })\n\n    # initialize kernel as empty array\n    kernel <- array(0, dim = c(ksize, ksize, 1, 1))\n    # populate kernel with Gaussian filter values\n    kernel[, , 1, 1] <- gauss\n\n    # display kernel values\n    print(\"Resulting kernel:\")\n    print(kernel[, , 1, 1])\n\n    # convolve image with kernel\n    img_flt <- apply_convolution(img, kernel)\n    return(img_flt)\n}\n\n# apply Gaussian filter to image with sigma = 1\nimg_gauss_1 <- apply_gaussian(img, ksize = 5, sigma = 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Resulting kernel:\"\n           [,1]      [,2]      [,3]      [,4]       [,5]\n[1,] 0.01831564 0.0820850 0.1353353 0.0820850 0.01831564\n[2,] 0.08208500 0.3678794 0.6065307 0.3678794 0.08208500\n[3,] 0.13533528 0.6065307 1.0000000 0.6065307 0.13533528\n[4,] 0.08208500 0.3678794 0.6065307 0.3678794 0.08208500\n[5,] 0.01831564 0.0820850 0.1353353 0.0820850 0.01831564\n```\n:::\n\n```{.r .cell-code}\n# apply Gaussian filter to image with sigma = 2\nimg_gauss_2 <- apply_gaussian(img, ksize = 5, sigma = 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Resulting kernel:\"\n          [,1]      [,2]      [,3]      [,4]      [,5]\n[1,] 0.3678794 0.5352614 0.6065307 0.5352614 0.3678794\n[2,] 0.5352614 0.7788008 0.8824969 0.7788008 0.5352614\n[3,] 0.6065307 0.8824969 1.0000000 0.8824969 0.6065307\n[4,] 0.5352614 0.7788008 0.8824969 0.7788008 0.5352614\n[5,] 0.3678794 0.5352614 0.6065307 0.5352614 0.3678794\n```\n:::\n\n```{.r .cell-code}\n# show resulting images side by side\nplot_img(img_gauss_1, \"Sigma = 1\") + plot_img(img_gauss_2, \"Sigma = 2\")\n```\n\n::: {.cell-output-display}\n![](filters_files/figure-html/a-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nWe can see that the blurring effect from the Gaussian filter is stronger with a greater sigma value.\n\n\\newpage\n\n## (b)\nImplement convolution process of convolving a 3 x 3 Sobel filters (S~x~ and S~y~) with the output images you obtained in step a. Plot the outputs of this process.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# define Sobel kernel Sx\nsobel_x <- array(\n    c(\n        -1, 0, 1,\n        -2, 0, 2,\n        -1, 0, 1\n    ),\n    dim = c(3, 3, 1, 1)\n)\n\n# define Sobel kernel Sy\nsobel_y <- array(\n    c(\n        -1, -2, -1,\n        0, 0, 0,\n        1, 2, 1\n    ),\n    dim = c(3, 3, 1, 1)\n)\n```\n:::\n\n\nApplying Sobel filters to Image with Gaussian filter where &sigma; = 1:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# apply Sobel filters to first Gaussian filter output\nimg_g1_sx <- apply_convolution(img_gauss_1, sobel_x) # x filter\nimg_g1_sy <- apply_convolution(img_gauss_1, sobel_y) # y filter\n\n# show resulting images side by side\nplot_img(img_g1_sx, \"Sigma = 1, Sobel x\") +\n    plot_img(img_g1_sy, \"Sigma = 1, Sobel y\")\n```\n\n::: {.cell-output-display}\n![](filters_files/figure-html/b-2-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nApplying Sobel filters to Image with Gaussian filter where &sigma; = 2:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# apply Sobel filters to second Gaussian filter output\nimg_g2_sx <- apply_convolution(img_gauss_2, sobel_x) # x filter\nimg_g2_sy <- apply_convolution(img_gauss_2, sobel_y) # y filter\n\n# Show resulting images side by side\nplot_img(img_g2_sx, \"Sigma = 2, Sobel x\") +\n    plot_img(img_g2_sy, \"Sigma = 2, Sobel y\")\n```\n\n::: {.cell-output-display}\n![](filters_files/figure-html/b-3-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nEdge detection is a bit sharper with the lower sigma value, however this comes at the cost of increased noise.\n\n\\newpage\n\n## (c)\nImplement convolution process of convolving Image 1 with $\\frac{\\partial G}{\\partial x}$ and $\\frac{\\partial G}{\\partial y}$ filters (5 x 5 filters and for &sigma; = 1 and 2).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# function applies first partial x-derivative Gaussian filter to an image\napply_d_gaussian_x <- function(img, ksize, sigma) {\n    # initialize x and y vectors around 0, e.g. [-2, -1, 0, 1, 2]\n    center <- floor(ksize / 2)\n    x <- y <- seq(-center, center, 1)\n\n    # first derivative of Gaussian function wrt x\n    dgauss <- outer(x, y, function(x, y) {\n        (-x / sigma^2) * exp(-(x^2 + y^2) / (2 * sigma^2))\n    })\n\n    # initialize kernel as empty array\n    kernel <- array(0, dim = c(ksize, ksize, 1, 1))\n    # populate kernel with x-derivative Gaussian filter values\n    kernel[, , 1, 1] <- dgauss\n\n    # display kernel values\n    print(\"Resulting kernel:\")\n    print(kernel[, , 1, 1])\n\n    # convolve image with kernel window\n    img_flt <- apply_convolution(img, kernel)\n    return(img_flt)\n}\n\n# function applies first partial y-derivative Gaussian filter to an image\napply_d_gaussian_y <- function(img, ksize, sigma) {\n    # initialize x and y vectors around 0, e.g. [-2, -1, 0, 1, 2]\n    center <- floor(ksize / 2)\n    x <- y <- seq(-center, center, 1)\n\n    # first derivative of Gaussian function wrt y\n    dgauss <- outer(x, y, function(x, y) {\n        (-y / sigma^2) * exp(-(x^2 + y^2) / (2 * sigma^2))\n    })\n\n    # initialize kernel as empty array\n    kernel <- array(0, dim = c(ksize, ksize, 1, 1))\n    # populate kernel with y-derivative Gaussian filter values\n    kernel[, , 1, 1] <- dgauss\n\n    # display kernel values\n    print(\"Resulting kernel:\")\n    print(kernel[, , 1, 1])\n\n    # convolve image with kernel window\n    img_flt <- apply_convolution(img, kernel)\n    return(img_flt)\n}\n\n# apply derivative Gaussian filters to Image with sigma = 1\nimg_dg1_x <- apply_d_gaussian_x(img, ksize = 5, sigma = 1) # x-derivative\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Resulting kernel:\"\n            [,1]       [,2]       [,3]       [,4]        [,5]\n[1,]  0.03663128  0.1641700  0.2706706  0.1641700  0.03663128\n[2,]  0.08208500  0.3678794  0.6065307  0.3678794  0.08208500\n[3,]  0.00000000  0.0000000  0.0000000  0.0000000  0.00000000\n[4,] -0.08208500 -0.3678794 -0.6065307 -0.3678794 -0.08208500\n[5,] -0.03663128 -0.1641700 -0.2706706 -0.1641700 -0.03663128\n```\n:::\n\n```{.r .cell-code}\nimg_dg1_y <- apply_d_gaussian_y(img, ksize = 5, sigma = 1) # y-derivative\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Resulting kernel:\"\n           [,1]      [,2] [,3]       [,4]        [,5]\n[1,] 0.03663128 0.0820850    0 -0.0820850 -0.03663128\n[2,] 0.16417000 0.3678794    0 -0.3678794 -0.16417000\n[3,] 0.27067057 0.6065307    0 -0.6065307 -0.27067057\n[4,] 0.16417000 0.3678794    0 -0.3678794 -0.16417000\n[5,] 0.03663128 0.0820850    0 -0.0820850 -0.03663128\n```\n:::\n\n```{.r .cell-code}\n# apply derivative Gaussian filters to Image with sigma = 2\nimg_dg2_x <- apply_d_gaussian_x(img, ksize = 5, sigma = 2) # x-derivative\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Resulting kernel:\"\n           [,1]       [,2]       [,3]       [,4]       [,5]\n[1,]  0.1839397  0.2676307  0.3032653  0.2676307  0.1839397\n[2,]  0.1338154  0.1947002  0.2206242  0.1947002  0.1338154\n[3,]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000\n[4,] -0.1338154 -0.1947002 -0.2206242 -0.1947002 -0.1338154\n[5,] -0.1839397 -0.2676307 -0.3032653 -0.2676307 -0.1839397\n```\n:::\n\n```{.r .cell-code}\nimg_dg2_y <- apply_d_gaussian_y(img, ksize = 5, sigma = 2) # y-derivative\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Resulting kernel:\"\n          [,1]      [,2] [,3]       [,4]       [,5]\n[1,] 0.1839397 0.1338154    0 -0.1338154 -0.1839397\n[2,] 0.2676307 0.1947002    0 -0.1947002 -0.2676307\n[3,] 0.3032653 0.2206242    0 -0.2206242 -0.3032653\n[4,] 0.2676307 0.1947002    0 -0.1947002 -0.2676307\n[5,] 0.1839397 0.1338154    0 -0.1338154 -0.1839397\n```\n:::\n\n```{.r .cell-code}\n# Show resulting images\nplot_img(img_dg1_x, \"Sigma = 1, Derivative Gaussian x\") +\n    plot_img(img_dg1_y, \"Sigma = 1, Derivative Gaussian y\")\n```\n\n::: {.cell-output-display}\n![](filters_files/figure-html/c-1.png){fig-align='center' width=672}\n:::\n\n```{.r .cell-code}\nplot_img(img_dg2_x, \"Sigma = 2, Derivative Gaussian x\") +\n    plot_img(img_dg2_y, \"Sigma = 2, Derivative Gaussian y\")\n```\n\n::: {.cell-output-display}\n![](filters_files/figure-html/c-2.png){fig-align='center' width=672}\n:::\n:::\n\n\n\\newpage\n\n### Please explain what do you observe comparing the results of step b and c?\nStep b utilized edge detection using the Sobel filter for x and y, and step c utilized the first derivative Gaussian filter for x and y. We can plot a review of the output images below:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# plot images generated from sigma = 1\nplot_img(img_g1_sx, \"Sigma = 1, Sobel x\") +\n    plot_img(img_g1_sy, \"Sigma = 1, Sobel y\") +\n    plot_img(img_dg1_x, \"Sigma = 1, Derivative Gaussian x\") +\n    plot_img(img_dg1_y, \"Sigma = 1, Derivative Gaussian y\") +\n    plot_layout(ncol = 2)\n```\n\n::: {.cell-output-display}\n![](filters_files/figure-html/compare-1.png){fig-align='center' width=672}\n:::\n\n```{.r .cell-code}\n# plot images generated from sigma = 2\nplot_img(img_g2_sx, \"Sigma = 2, Sobel x\") +\n    plot_img(img_g2_sy, \"Sigma = 2, Sobel y\") +\n    plot_img(img_dg2_x, \"Sigma = 2, Derivative Gaussian x\") +\n    plot_img(img_dg2_y, \"Sigma = 2, Derivative Gaussian y\") +\n    plot_layout(ncol = 2)\n```\n\n::: {.cell-output-display}\n![](filters_files/figure-html/compare-2.png){fig-align='center' width=672}\n:::\n:::\n\n\nFrom the rasterizations above, we can see that both filters are effective at their main goal of edge detection. On it's own, the Sobel filters is known to be sensitive to noise, and so we first filtered the image using Gaussian filters before applying the Sobel filters. The first derivative Gaussian filter does not have as much sensitivity. One noticeable difference is the opposite visual effects the filters have; the edges that appear to be protruding in the Sobel filter, appear to be sunken in the derivative Gaussian filter. This likely results from how the two filters emphasize the orientation of edges, with opposite negative and positive values in the resulting image. Finally, another difference observed between the two filters is that the edges are lighter and thicker with the Sobel filters, whilst the edges are darker and sharper with the derivative Gaussian filter (albeit to a slim extent). This may be attributed to the extra step of pre-filtering the image with a Gaussian filter before applying the Sobel filter, which adds an extra level of blur. On the other hand, the derivative Gaussian filter both removes noise and detects edges in one filter, which removes an extra step needed, also resulting in less of a blurring effect.\n\n\\newpage\n\n# 2. Corner Detection\n\nImplement Harris Corner Detection algorithm step by step as explained in the class. Apply your script to detect corners in image 1. Plot the corner response map, and the non-maximum suppression output.\n\n## Setup: define parameters used in Harris Corner Detection\n\n::: {.cell}\n\n```{.r .cell-code}\n# window size for Gaussian filter (w x w)\nw <- 5\n# sigma for Gaussian filter\nsigma <- 1\n\n# empirically determined constant used in corner response calculation\nk <- 0.04\n```\n:::\n\n\n## Step 1. Spatial derivative calculation\n\n::: {.cell}\n\n```{.r .cell-code}\n# apply Sobel filters to Image\nI_x <- apply_convolution(img, sobel_x)\nI_y <- apply_convolution(img, sobel_y)\n\n# compute products of derivatives\nI_xx <- I_x^2\nI_yy <- I_y^2\nI_xy <- I_x * I_y\n```\n:::\n\n\n\\newpage\n\n## Step 2. Structure tensor setup (M)\n\n::: {.cell}\n\n```{.r .cell-code}\n# compute sums of products of derivatives\nS_xx <- apply_gaussian(I_xx, w, sigma)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Resulting kernel:\"\n           [,1]      [,2]      [,3]      [,4]       [,5]\n[1,] 0.01831564 0.0820850 0.1353353 0.0820850 0.01831564\n[2,] 0.08208500 0.3678794 0.6065307 0.3678794 0.08208500\n[3,] 0.13533528 0.6065307 1.0000000 0.6065307 0.13533528\n[4,] 0.08208500 0.3678794 0.6065307 0.3678794 0.08208500\n[5,] 0.01831564 0.0820850 0.1353353 0.0820850 0.01831564\n```\n:::\n\n```{.r .cell-code}\nS_yy <- apply_gaussian(I_yy, w, sigma)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Resulting kernel:\"\n           [,1]      [,2]      [,3]      [,4]       [,5]\n[1,] 0.01831564 0.0820850 0.1353353 0.0820850 0.01831564\n[2,] 0.08208500 0.3678794 0.6065307 0.3678794 0.08208500\n[3,] 0.13533528 0.6065307 1.0000000 0.6065307 0.13533528\n[4,] 0.08208500 0.3678794 0.6065307 0.3678794 0.08208500\n[5,] 0.01831564 0.0820850 0.1353353 0.0820850 0.01831564\n```\n:::\n\n```{.r .cell-code}\nS_xy <- apply_gaussian(I_xy, w, sigma)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Resulting kernel:\"\n           [,1]      [,2]      [,3]      [,4]       [,5]\n[1,] 0.01831564 0.0820850 0.1353353 0.0820850 0.01831564\n[2,] 0.08208500 0.3678794 0.6065307 0.3678794 0.08208500\n[3,] 0.13533528 0.6065307 1.0000000 0.6065307 0.13533528\n[4,] 0.08208500 0.3678794 0.6065307 0.3678794 0.08208500\n[5,] 0.01831564 0.0820850 0.1353353 0.0820850 0.01831564\n```\n:::\n\n```{.r .cell-code}\n# note: see Edge Detection (a) for implementation of apply_gaussian()\n\n# initialize empty matrix M to store sums\nM <- array(0, dim = c(nrow(img), ncol(img), 2, 2))\n\n# populate matrix M with sums\nfor (i in seq_len(nrow(img))) {\n    for (j in seq_len(ncol(img))) {\n        # insert 2x2 matrix for each pixel\n        M[i, j, , ] <- matrix(\n            c(\n                S_xx[i, j, , ], S_xy[i, j, , ],\n                S_xy[i, j, , ], S_yy[i, j, , ]\n            ),\n            nrow = 2\n        )\n    }\n}\n```\n:::\n\n\n\\newpage\n\n## Step 3. Corner response calculation\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# initialize empty matrix R to store measure of corner response\nR <- array(0, dim = c(nrow(img), ncol(img), 1, 1))\n\n# populate matrix R with corner responses per pixel\nfor (i in seq_len(nrow(img))) {\n    for (j in seq_len(ncol(img))) {\n        # extract matrix M for current pixel\n        M_ij <- matrix(M[i, j, , ], nrow = 2, ncol = 2)\n\n        # compute eigenvalues\n        eigenM <- eigen(M_ij)\n        lambda1 <- eigenM$values[1] # first eigenvalue of current M\n        lambda2 <- eigenM$values[2] # second eigenvalue of current M\n\n        # compute determinant and trace using eigenvalues\n        detM <- lambda1 * lambda2\n        traceM <- lambda1 + lambda2\n\n        # compute corner response and add to matrix R\n        R[i, j, , ] <- detM - k * traceM^2\n    }\n}\n\n# plot results\ncorner_response_map <- as.cimg(R)\nplot_img(corner_response_map, \"Corner response map\")\n```\n\n::: {.cell-output-display}\n![](filters_files/figure-html/harris3-1.png){fig-align='center' width=576}\n:::\n:::\n\n\nIn our corner response map, we can see that white areas correspond to corners, and black areas correspond to edges.\n\n\\newpage\n\n## Step 4. Non-maximum suppression\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# view summary of our corner responses\nsummary(R)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n-49.03308  -0.01485   0.00000  -0.02343   0.00059 202.64260 \n```\n:::\n\n```{.r .cell-code}\n# view histogram of our corner responses\nhist(R, breaks = 100, xlab = \"Corner response value\")\n```\n\n::: {.cell-output-display}\n![](filters_files/figure-html/harris4-1-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nFrom our summary, we can see the the values are distributed around a center of approximately 0. Since greater positive values correspond to a higher corner detection response, I can set a threshold of 0 to capture any pixels with a positive value. In the histogram, we can see that the vast majority of pixels have a value of around 0, while very few have values over 50, or even 25. We can increase the threshold up depending on how sharply we want to define where corners are detected.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# corner R value threshold\nthreshold <- 0\n\n# keep only values meeting threshold, setting otherwise to 0 (black)\nR_thr <- R\nR_thr[R_thr < threshold] <- 0\n\n# plot results\nnon_max_suppression <- as.cimg(R_thr)\nplot_img(non_max_suppression, \"Non-max suppression, threshold = 0\")\n```\n\n::: {.cell-output-display}\n![](filters_files/figure-html/harris4-2-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nIn this image, only corners are displayed in white, while all other non-corner pixels are left out of the image (i.e. are black). We can see that the Harris corner detection highlights the corners of each window of the building, as well as corners of the roof and building itself.\n\nFor comparison's sake, we can increase the threshold to only include pixels with a much higher positive corner response:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# increased corner R value threshold\nthreshold <- 80\n\n# plot results\nR_thr <- R\nR_thr[R_thr < threshold] <- 0\nnon_max_suppression <- as.cimg(R_thr)\nplot_img(non_max_suppression, \"Non-max suppression, threshold = 80\")\n```\n\n::: {.cell-output-display}\n![](filters_files/figure-html/harris4-3-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nHere our results are much sharper and excludes possible corners brought about by noise.",
    "supporting": [
      "filters_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}